
ML helps machines/computers get smarter. 

Trained systems can be used both for monitoring and prevention.

These systems can be used maliciously as well.

# Poisoning the training data

Attackers send modified training data that causes the AI to behave incorrectly (or can make it work acc to the way they want)

# Evasion Attacks

The AI is only as good as its training.

An AI that has been on a certain kind of spam signature, can be fooled by using a different approach.

AI that uses real-world SPII/ PII info can be tricked into revealing it as well.

# Prevention

--> The learning algorithms should be secure
--> Quality training data should be used
--> Constantly retrain the model with new data
--> Train the AI with possible poisoning/ simulate attackers to tune how the AI responds


